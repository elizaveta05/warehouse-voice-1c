import queue
import sounddevice as sd
import wave
import os
import requests
import time
import io
import json
from vosk import Model, KaldiRecognizer
from faster_whisper import WhisperModel

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
SAMPLERATE = 16000
CHANNELS = 1
TRIGGER_PHRASE = "–Ω–∞—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ"
SERVER_URL = "http://localhost:8000"  

# === VOSK ===
vosk_model = Model(r"C:\vosk\vosk-model-small-ru-0.22")

vosk_recognizer = KaldiRecognizer(vosk_model, SAMPLERATE)

# === WHISPER ===
whisper = WhisperModel("small", device="cpu", compute_type="int8")

# === –û—á–µ—Ä–µ–¥—å –¥–ª—è –ø–æ—Ç–æ–∫–∞ –∞—É–¥–∏–æ ===
q = queue.Queue()

def audio_callback(indata, frames, time_, status):
    if status:
        print("‚ö†Ô∏è", status)
    q.put(bytes(indata))

def record_audio(duration_sec=4):
    """–°–æ–±–∏—Ä–∞–µ–º –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ –∫–∞–∫ bytes –≤ —Ñ–æ—Ä–º–∞—Ç–µ WAV"""
    audio_data = bytearray()
    target_bytes = SAMPLERATE * CHANNELS * 2 * duration_sec
    while len(audio_data) < target_bytes:
        audio_data.extend(q.get())

    wav_io = io.BytesIO()
    with wave.open(wav_io, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(2)
        wf.setframerate(SAMPLERATE)
        wf.writeframes(audio_data)
    wav_io.seek(0)
    return wav_io.read()

def transcribe_whisper(wav_bytes):
    """–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ faster-whisper"""
    try:
        with io.BytesIO(wav_bytes) as wf:
            segments, _ = whisper.transcribe(wf, beam_size=1)
            return " ".join(seg.text for seg in segments).strip()
    except Exception as e:
        print("‚ùå Whisper error:", e)
        return ""

def send_to_server(text):
    try:
        print("üß† –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:", text)
        resp = requests.post(f"{SERVER_URL}/recognize", files={
            "file": ("command.wav", io.BytesIO(text.encode()), "audio/wav")
        })
        if resp.ok:
            intent_data = resp.json()
            print("üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ 1–°:", intent_data)
            requests.post(f"{SERVER_URL}/command", json=intent_data)
        else:
            print("‚ùå –û—à–∏–±–∫–∞ /recognize:", resp.status_code)
    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ 1–°:", e)

def main():
    print("üéô –ê–≥–µ–Ω—Ç –∑–∞–ø—É—â–µ–Ω. –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ä—è—á–µ–π —Ñ—Ä–∞–∑—ã...")
    with sd.RawInputStream(samplerate=SAMPLERATE, blocksize=8000, dtype='int16',
                           channels=CHANNELS, callback=audio_callback):
        while True:
            data = q.get()
            if vosk_recognizer.AcceptWaveform(data):
                res = json.loads(vosk_recognizer.Result())
                text = res.get("text", "").lower()
                if TRIGGER_PHRASE in text:
                    print("üöÄ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≥–æ—Ä—è—á–∞—è —Ñ—Ä–∞–∑–∞:", text)
                    print("üëÇ –Ø –≤–∞—Å —Å–ª—É—à–∞—é...")
                    audio = record_audio(duration_sec=4)
                    result_text = transcribe_whisper(audio)
                    if result_text:
                        send_to_server(result_text)
                    else:
                        print("‚ö†Ô∏è –ö–æ–º–∞–Ω–¥–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞.")
                    print("‚Ü©Ô∏è –í–æ–∑–≤—Ä–∞—Ç –≤ —Ä–µ–∂–∏–º –æ–∂–∏–¥–∞–Ω–∏—è –≥–æ—Ä—è—á–µ–π —Ñ—Ä–∞–∑—ã...")

if __name__ == "__main__":
    main()
